{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Data\n",
    "Use data from the UCI ML repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx'\n",
    "retail_data = pd.read_excel(website_url) # This may take a couple minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_retail = retail_data.loc[pd.isnull(retail_data.CustomerID) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Now we have no missing values and all of the purchases can be matched to a specific customer.\n",
    "\n",
    "Before we make any sort of ratings matrix, it would be nice to have a lookup table that keep track of each item ID along with a description of that item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup = cleaned_retail[['StockCode', 'Description']].drop_duplicates() # Only get unique pairs\n",
    "item_lookup['StockCode'] = item_lookup.StockCode.astype(str) # Encode as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_retail['CustomerID'] = cleaned_retail.CustomerID.astype(int)\n",
    "cleaned_retail = cleaned_retail[['StockCode', 'Quantity', 'CustomerID']]\n",
    "grouped_cleaned = cleaned_retail.groupby(['CustomerID', 'StockCode']).sum().reset_index()\n",
    "grouped_cleaned.Quantity.loc[grouped_cleaned.Quantity == 0] = 1 # Replace a sum of zero purchases with one to indicate purchased\n",
    "grouped_purchased = grouped_cleaned.query('Quantity > 0') # Only get customers where purchase totals were positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>23166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347</td>\n",
       "      <td>16008</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12347</td>\n",
       "      <td>17021</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12347</td>\n",
       "      <td>20665</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12347</td>\n",
       "      <td>20719</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID StockCode  Quantity\n",
       "0       12346     23166         1\n",
       "1       12347     16008        24\n",
       "2       12347     17021        36\n",
       "3       12347     20665         6\n",
       "4       12347     20719        40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_purchased.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = list(np.sort(grouped_purchased.CustomerID.unique())) # Get our unique customers\n",
    "products = list(grouped_purchased.StockCode.unique()) # Get our unique products that were purchased\n",
    "quantity = list(grouped_purchased.Quantity) # All of our purchases\n",
    "\n",
    "rows = grouped_purchased.CustomerID.astype('category', categories=customers).cat.codes\n",
    "# Get the associated row indices\n",
    "cols = grouped_purchased.StockCode.astype('category', categories=products).cat.codes\n",
    "# Get the associated column indices\n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.32190920694744"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = purchases_sparse.shape[0]*purchases_sparse.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(purchases_sparse.nonzero()[0]) # Number of iterms interacted with \n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Training and Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With collaborative filtering, the traditional train/test split is not going to work because you need all of the user/item interactions to find the proper matrix factorization. A better method is to hide a certain percentage of the user/item interactions from the model during the training phase chosen at random. Then, check during the test phase how many of the items that were recommended the user actually ended up purchasing in the end. Ideally, you would ultimately test your recommendations with some kind of A/B test or utilizing data from a time series where all data prior to a certain point in time is used for training while data after a certain period of time is used for testing.\n",
    "\n",
    "Our test set is an exact copy of our original data. The training set, however, will mask a random percentage of user/item interactions and act as if the user never purchased the item (making it a sparse entry with a zero). We then check in the test set which items were recommended to the user that they ended up actually purchasing. If the users frequently ended up purchasing the items most recommended to them by the system, we can conclude the system seems to be working.\n",
    "\n",
    "As an additional check, we can compare our system to simply recommending the most popular items to every user (beating popularity is a bit difficult). This will be our baseline.\n",
    "\n",
    "This method of testing isn’t necessarily the “correct” answer, because it depends on how you want to use the recommender system. However, it is a practical way of testing performance I will use for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    \"\"\"\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    \"\"\"\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return our training set, a test set that has been binarized to 0/1 for purchased/not purchased, and a list of which users had at least one item masked. We will test the performance of the recommender system on these users only. I am masking 20% of the user/item interactions for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, product_users_altered = make_train(purchases_sparse, pct_test=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ALS for Implicit Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have our ratings matrix which is sparse (represented by the product_train sparse matrix object). We need to turn this into a **confidence matrix**\n",
    "\n",
    "$$C_{ui} = 1 + \\alpha r_{ui}$$\n",
    "\n",
    "Where $C_{ui}$ is the confidence matrix for our users $u$ and our items $i$. The $\\alpha$ term represents a linear scaling of the rating preferences (in our case number of purchases) and the $r_{ui}$ term is our original matrix of purchases. The paper suggests 40 as a good starting point.\n",
    "\n",
    "After taking the derivative of equation 3 in the paper, we can minimize the cost function for our users $U$:\n",
    "\n",
    "$$x_u = (Y^TC^uY + \\lambda I)^{-1}Y^TC^up(u)$$\n",
    "\n",
    "The authors note you can speed up this computation through some linear algebra that changes this equation to:\n",
    "\n",
    "$$x_u = (Y^TY + Y^T(C^u-I)Y+\\lambda I)^{-1}Y^TC^up(u)$$\n",
    "\n",
    "Notice that we can now precompute the $Y^TY$ portion without having to iterate through each user $u$. We can derive a similar equation for our items:\n",
    "\n",
    "$$y_i = (X^TX + X^T(C^i-1)X + \\lambda I) ^{-1}X^TC^ip(i)$$\n",
    "\n",
    "These will be the two equations we will iterate back and forth between until they converge. We also have a regularization term $\\lambda$ that can help prevent overfitting during the training stage as well, along with our binarized preference matrix $p$ which is just 1 where there was a purchase (or interation) and zero where there was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_weighted_ALS(training_set, lambda_val=0.1, alpha=40, iterations=10, rank_size=20, seed=0):\n",
    "    \"\"\"\n",
    "    Implicit weighted ALS taken from Hu, Koren and Volinsky 2008. Designed for ALS and implicit feedback based \n",
    "    collaborative filtering.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    training_set - Our matrix of ratings with shape m x n, where m is the number of users and n is the number of items.\n",
    "    Should be a sparse csr matrix to save space. \n",
    "    \n",
    "    lambda_val - Used for regularization during alternating least squares. Increasing this value may increase bias\n",
    "    but decrease variance. Default is 0.1. \n",
    "    \n",
    "    alpha - The parameter associated with the confidence matrix discussed in the paper, where Cui = 1 + alpha*Rui. \n",
    "    The paper found a default of 40 most effective. Decreasing this will decrease the variability in confidence between\n",
    "    various ratings.\n",
    "    \n",
    "    iterations - The number of times to alternate between both user feature vector and item feature vector in\n",
    "    alternating least squares. More iterations will allow better convergence at the cost of increased computation. \n",
    "    The authors found 10 iterations was sufficient, but more may be required to converge. \n",
    "    \n",
    "    rank_size - The number of latent features in the user/item feature vectors. The paper recommends varying this \n",
    "    between 20-200. Increasing the number of features may overfit but could reduce bias. \n",
    "    \n",
    "    seed - Set the seed for reproducible results\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The feature vectors for users and items. The dot product of these feature vectors should give you the expected \n",
    "    \"rating\" at each point in your original matrix.\n",
    "    \"\"\"\n",
    "    # first set up our confidence matrix\n",
    "    \n",
    "    conf = (alpha*training_set) # To allow the matrix to stay sparse, I will add one later when each row is taken \n",
    "                                # and converted to dense. \n",
    "    num_user = conf.shape[0]\n",
    "    num_item = conf.shape[1] # Get the size of our original ratings matrix, m x n\n",
    "    \n",
    "    # initialize our X/Y feature vectors randomly with a set seed\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    \n",
    "    X = sparse.csr_matrix(rstate.normal(size = (num_user, rank_size))) # Random numbers in a m x rank shape\n",
    "    Y = sparse.csr_matrix(rstate.normal(size = (num_item, rank_size))) # Normally this would be rank x n but we can \n",
    "                                                                 # transpose at the end. Makes calculation more simple.\n",
    "    X_eye = sparse.eye(num_user)\n",
    "    Y_eye = sparse.eye(num_item)\n",
    "    lambda_eye = lambda_val * sparse.eye(rank_size) # Our regularization term lambda*I. \n",
    "    \n",
    "    # We can compute this before iteration starts. \n",
    "    \n",
    "    # Begin iterations\n",
    "   \n",
    "    for iter_step in range(iterations): # Iterate back and forth between solving X given fixed Y and vice versa\n",
    "        # Compute yTy and xTx at beginning of each iteration to save computing time\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "        # Being iteration to solve for X based on fixed Y\n",
    "        for u in range(num_user):\n",
    "            conf_samp = conf[u,:].toarray() # Grab user row from confidence matrix and convert to dense\n",
    "            pref = conf_samp.copy() \n",
    "            pref[pref != 0] = 1 # Create binarized preference vector \n",
    "            CuI = sparse.diags(conf_samp, [0]) # Get Cu - I term, don't need to subtract 1 since we never added it \n",
    "            yTCuIY = Y.T.dot(CuI).dot(Y) # This is the yT(Cu-I)Y term \n",
    "            yTCupu = Y.T.dot(CuI + Y_eye).dot(pref.T) # This is the yTCuPu term, where we add the eye back in\n",
    "                                                      # Cu - I + I = Cu\n",
    "            X[u] = spsolve(yTy + yTCuIY + lambda_eye, yTCupu) \n",
    "            # Solve for Xu = ((yTy + yT(Cu-I)Y + lambda*I)^-1)yTCuPu, equation 4 from the paper  \n",
    "        # Begin iteration to solve for Y based on fixed X \n",
    "        for i in range(num_item):\n",
    "            conf_samp = conf[:,i].T.toarray() # transpose to get it in row format and convert to dense\n",
    "            pref = conf_samp.copy()\n",
    "            pref[pref != 0] = 1 # Create binarized preference vector\n",
    "            CiI = sparse.diags(conf_samp, [0]) # Get Ci - I term, don't need to subtract 1 since we never added it\n",
    "            xTCiIX = X.T.dot(CiI).dot(X) # This is the xT(Cu-I)X term\n",
    "            xTCiPi = X.T.dot(CiI + X_eye).dot(pref.T) # This is the xTCiPi term\n",
    "            Y[i] = spsolve(xTx + xTCiIX + lambda_eye, xTCiPi)\n",
    "            # Solve for Yi = ((xTx + xT(Cu-I)X) + lambda*I)^-1)xTCiPi, equation 5 from the paper\n",
    "    # End iterations\n",
    "    return X, Y.T # Transpose at the end to make up for not being transposed at the beginning. \n",
    "                         # Y needs to be rank x n. Keep these as separate matrices for scale reasons. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vects, item_vecs = implicit_weighted_ALS(product_train, lambda_val=0.1, alpha=15, rank_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05851164, -0.0087325 , -0.00229653,  0.0138245 ,  0.01932942])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vects[0, :].dot(item_vecs).toarray()[0, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding Up ALS\n",
    "This code in its raw form is just too slow. We have to do a lot of looping, and we haven’t taken advantage of the fact that our algorithm is embarrasingly parallel, since we could do each iteration of the item and user vectors independently. Fortunately, as I was still finishing this up, Ben Frederickson at Flipboard had perfect timing and came out with a version of ALS for Python utilizing Cython and parallelizing the code among threads. You can read his blog post about using it for finding similar music artists using matrix factorization here and his implicit library here. He claims it is even faster than Quora’s C++ QMF, but I haven’t tried theirs. All I can tell you is that it is over 1000 times faster than this bare bones pure Python version when I tested it. Install this library before you continue and follow the instructions. If you have conda installed, just do pip install implicit and you should be good to go.\n",
    "\n",
    "First, import his library so we can utilize it for our matrix factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.als import AlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50.0/50 [00:00<00:00, 50.26it/s]\n"
     ]
    }
   ],
   "source": [
    "alpha = 15\n",
    "model = AlternatingLeastSquares(factors=20, regularization=0.1, iterations=50)\n",
    "model.fit(product_train.transpose()*alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vecs = model.user_factors\n",
    "item_vecs = model.item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Recommender System\n",
    "Remember that our training set had 20% of the purchases masked? This will allow us to evaluate the performance of our recommender system. Essentially, we need to see if the order of recommendations given for each user matches the items they ended up purchasing. A commonly used metric for this kind of problem is the area under the Receiver Operating Characteristic (or ROC) curve. A greater area under the curve means we are recommending items that end up being purchased near the top of the list of recommended items. Usually this metric is used in more typical binary classification problems to identify how well a model can predict a positive example vs. a negative one. It will also work well for our purposes of ranking recommendations.\n",
    "\n",
    "In order to do that, we need to write a function that can calculate a mean area under the curve (AUC) for any user that had at least one masked item. As a benchmark, we will also calculate what the mean AUC would have been if we had simply recommended the most popular items. Popularity tends to be hard to beat in most recommender system problems, so it makes a good comparison.\n",
    "\n",
    "First, let’s make a simple function that can calculate our AUC. Scikit-learn has one we can alter a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.roc_auc_score(test, predictions)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, utilize this helper function inside of a second function that will calculate the AUC for each user in our training set that had at least one item masked. It should also calculate AUC for the most popular items for our users to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    \"\"\"\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    training_set - The training set resulting from make_train, where a certain percentage of user/item interactions are reset\n",
    "                   to hide them from the model.\n",
    "                   \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function.\n",
    "                   \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the MF.\n",
    "                  These should be stored in a list, with user vectors as item zero and item vectors as item one.\n",
    "                  \n",
    "    test_set - The test set constructed earlier from make_train functions\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The mean AUC (area under the ROC curve) of the test set only on user-item interactions.\n",
    "    There were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    \"\"\"\n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1)\n",
    "\n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.auc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.871, 0.814)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mean_auc(product_train, product_users_altered, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_purchased(customer_id, mf_train, customers_list, products_list, item_lookup):\n",
    "    '''\n",
    "    This just tells me which items have been already purchased by a specific user in the training set. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    customer_id - Input the customer's id number that you want to see prior purchases of at least once\n",
    "    \n",
    "    mf_train - The initial ratings training set used (without weights applied)\n",
    "    \n",
    "    customers_list - The array of customers used in the ratings matrix\n",
    "    \n",
    "    products_list - The array of products used in the ratings matrix\n",
    "    \n",
    "    item_lookup - A simple pandas dataframe of the unique product ID/product descriptions available\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    A list of item IDs and item descriptions for a particular customer that were already purchased in the training set\n",
    "    '''\n",
    "    cust_ind = np.where(customers_list == customer_id)[0][0] # Returns the index row of our customer id\n",
    "    purchased_ind = mf_train[cust_ind,:].nonzero()[1] # Get column indices of purchased items\n",
    "    prod_codes = products_list[purchased_ind] # Get the stock codes for our purchased items\n",
    "    return item_lookup.loc[item_lookup.StockCode.isin(prod_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_arr = np.array(customers) # Array of customer IDs from the ratings matrix\n",
    "products_arr = np.array(products) # Array of product IDs from the ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12346, 12347, 12348, 12349, 12350])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_arr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61619</th>\n",
       "      <td>23166</td>\n",
       "      <td>MEDIUM CERAMIC TOP STORAGE JAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StockCode                     Description\n",
       "61619     23166  MEDIUM CERAMIC TOP STORAGE JAR"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_purchased(12346, product_train, customers_arr, products_arr, item_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_items(customer_id, mf_train, user_vecs, item_vecs, customer_list, item_list, item_lookup, num_items = 10):\n",
    "    '''\n",
    "    This function will return the top recommended items to our users \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    customer_id - Input the customer's id number that you want to get recommendations for\n",
    "    \n",
    "    mf_train - The training matrix you used for matrix factorization fitting\n",
    "    \n",
    "    user_vecs - the user vectors from your fitted matrix factorization\n",
    "    \n",
    "    item_vecs - the item vectors from your fitted matrix factorization\n",
    "    \n",
    "    customer_list - an array of the customer's ID numbers that make up the rows of your ratings matrix \n",
    "                    (in order of matrix)\n",
    "    \n",
    "    item_list - an array of the products that make up the columns of your ratings matrix\n",
    "                    (in order of matrix)\n",
    "    \n",
    "    item_lookup - A simple pandas dataframe of the unique product ID/product descriptions available\n",
    "    \n",
    "    num_items - The number of items you want to recommend in order of best recommendations. Default is 10. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    - The top n recommendations chosen based on the user/item vectors for items never interacted with/purchased\n",
    "    '''\n",
    "    \n",
    "    cust_ind = np.where(customer_list == customer_id)[0][0] # Returns the index row of our customer id\n",
    "    pref_vec = mf_train[cust_ind,:].toarray() # Get the ratings from the training set ratings matrix\n",
    "    pref_vec = pref_vec.reshape(-1) + 1 # Add 1 to everything, so that items not purchased yet become equal to 1\n",
    "    pref_vec[pref_vec > 1] = 0 # Make everything already purchased zero\n",
    "    rec_vector = user_vecs[cust_ind,:].dot(item_vecs.T) # Get dot product of user vector and all item vectors\n",
    "    # Scale this recommendation vector between 0 and 1\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0] \n",
    "    recommend_vector = pref_vec*rec_vector_scaled \n",
    "    # Items already purchased have their recommendation multiplied by zero\n",
    "    product_idx = np.argsort(recommend_vector)[::-1][:num_items] # Sort the indices of the items into order \n",
    "    # of best recommendations\n",
    "    rec_list = [] # start empty list to store items\n",
    "    for index in product_idx:\n",
    "        code = item_list[index]\n",
    "        rec_list.append([code, item_lookup.Description.loc[item_lookup.StockCode == code].iloc[0]]) \n",
    "        # Append our descriptions to the list\n",
    "    codes = [item[0] for item in rec_list]\n",
    "    descriptions = [item[1] for item in rec_list]\n",
    "    final_frame = pd.DataFrame({'StockCode': codes, 'Description': descriptions}) # Create a dataframe \n",
    "    return final_frame[['StockCode', 'Description']] # Switch order of columns around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23167</td>\n",
       "      <td>SMALL CERAMIC TOP STORAGE JAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23165</td>\n",
       "      <td>LARGE CERAMIC TOP STORAGE JAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23168</td>\n",
       "      <td>CLASSIC SUGAR DISPENSER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23294</td>\n",
       "      <td>SET OF 6 SNACK LOAF BAKING CASES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22978</td>\n",
       "      <td>PANTRY ROLLING PIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22963</td>\n",
       "      <td>JAM JAR WITH GREEN LID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22980</td>\n",
       "      <td>PANTRY SCRUBBING BRUSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23295</td>\n",
       "      <td>SET OF 12 MINI LOAF BAKING CASES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22982</td>\n",
       "      <td>PANTRY PASTRY BRUSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22962</td>\n",
       "      <td>JAM JAR WITH PINK LID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StockCode                       Description\n",
       "0     23167    SMALL CERAMIC TOP STORAGE JAR \n",
       "1     23165     LARGE CERAMIC TOP STORAGE JAR\n",
       "2     23168           CLASSIC SUGAR DISPENSER\n",
       "3     23294  SET OF 6 SNACK LOAF BAKING CASES\n",
       "4     22978                PANTRY ROLLING PIN\n",
       "5     22963            JAM JAR WITH GREEN LID\n",
       "6     22980            PANTRY SCRUBBING BRUSH\n",
       "7     23295  SET OF 12 MINI LOAF BAKING CASES\n",
       "8     22982               PANTRY PASTRY BRUSH\n",
       "9     22962             JAM JAR WITH PINK LID"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_items(12346, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,\n",
    "                       num_items = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>37446</td>\n",
       "      <td>MINI CAKE STAND WITH HANGING CAKES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>37449</td>\n",
       "      <td>CERAMIC CAKE STAND + HANGING CAKES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>37450</td>\n",
       "      <td>CERAMIC CAKE BOWL + HANGING CAKES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>22890</td>\n",
       "      <td>NOVELTY BISCUITS CAKE STAND 3 TIER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     StockCode                         Description\n",
       "2148     37446  MINI CAKE STAND WITH HANGING CAKES\n",
       "2149     37449  CERAMIC CAKE STAND + HANGING CAKES\n",
       "4859     37450   CERAMIC CAKE BOWL + HANGING CAKES\n",
       "5108     22890  NOVELTY BISCUITS CAKE STAND 3 TIER"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_purchased(12353, product_train, customers_arr, products_arr, item_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22055</td>\n",
       "      <td>MINI CAKE STAND  HANGING STRAWBERY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37447</td>\n",
       "      <td>CERAMIC CAKE DESIGN SPOTTED PLATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22059</td>\n",
       "      <td>CERAMIC STRAWBERRY DESIGN MUG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22057</td>\n",
       "      <td>CERAMIC PLATE STRAWBERRY DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37448</td>\n",
       "      <td>CERAMIC CAKE DESIGN SPOTTED MUG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22645</td>\n",
       "      <td>CERAMIC HEART FAIRY CAKE MONEY BANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22644</td>\n",
       "      <td>CERAMIC CHERRY CAKE MONEY BANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22649</td>\n",
       "      <td>STRAWBERRY FAIRY CAKE TEAPOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21232</td>\n",
       "      <td>STRAWBERRY CERAMIC TRINKET BOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22063</td>\n",
       "      <td>CERAMIC BOWL WITH STRAWBERRY DESIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StockCode                          Description\n",
       "0     22055   MINI CAKE STAND  HANGING STRAWBERY\n",
       "1     37447    CERAMIC CAKE DESIGN SPOTTED PLATE\n",
       "2     22059        CERAMIC STRAWBERRY DESIGN MUG\n",
       "3     22057      CERAMIC PLATE STRAWBERRY DESIGN\n",
       "4     37448      CERAMIC CAKE DESIGN SPOTTED MUG\n",
       "5     22645  CERAMIC HEART FAIRY CAKE MONEY BANK\n",
       "6     22644       CERAMIC CHERRY CAKE MONEY BANK\n",
       "7     22649         STRAWBERRY FAIRY CAKE TEAPOT\n",
       "8     21232       STRAWBERRY CERAMIC TRINKET BOX\n",
       "9     22063  CERAMIC BOWL WITH STRAWBERRY DESIGN"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_items(12353, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,\n",
    "                       num_items = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>22326</td>\n",
       "      <td>ROUND SNACK BOXES SET OF4 WOODLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>22629</td>\n",
       "      <td>SPACEBOY LUNCH BOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>22631</td>\n",
       "      <td>CIRCUS PARADE LUNCH BOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>20725</td>\n",
       "      <td>LUNCH BAG RED RETROSPOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>22382</td>\n",
       "      <td>LUNCH BAG SPACEBOY DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>22328</td>\n",
       "      <td>ROUND SNACK BOXES SET OF 4 FRUITS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>22630</td>\n",
       "      <td>DOLLY GIRL LUNCH BOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>22555</td>\n",
       "      <td>PLASTERS IN TIN STRONGMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58132</th>\n",
       "      <td>20725</td>\n",
       "      <td>LUNCH BAG RED SPOTTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      StockCode                          Description\n",
       "34        22326  ROUND SNACK BOXES SET OF4 WOODLAND \n",
       "35        22629                  SPACEBOY LUNCH BOX \n",
       "37        22631             CIRCUS PARADE LUNCH BOX \n",
       "93        20725              LUNCH BAG RED RETROSPOT\n",
       "369       22382           LUNCH BAG SPACEBOY DESIGN \n",
       "547       22328   ROUND SNACK BOXES SET OF 4 FRUITS \n",
       "549       22630                 DOLLY GIRL LUNCH BOX\n",
       "1241      22555            PLASTERS IN TIN STRONGMAN\n",
       "58132     20725                 LUNCH BAG RED SPOTTY"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_items_purchased(12361, product_train, customers_arr, products_arr, item_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20727</td>\n",
       "      <td>LUNCH BAG  BLACK SKULL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20726</td>\n",
       "      <td>LUNCH BAG WOODLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22662</td>\n",
       "      <td>LUNCH BAG DOLLY GIRL DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23207</td>\n",
       "      <td>LUNCH BAG ALPHABET DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20719</td>\n",
       "      <td>WOODLAND CHARLOTTE BAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22383</td>\n",
       "      <td>LUNCH BAG SUKI  DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20728</td>\n",
       "      <td>LUNCH BAG CARS BLUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23206</td>\n",
       "      <td>LUNCH BAG APPLE DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22355</td>\n",
       "      <td>CHARLOTTE BAG SUKI DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23209</td>\n",
       "      <td>LUNCH BAG DOILEY PATTERN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StockCode                  Description\n",
       "0     20727      LUNCH BAG  BLACK SKULL.\n",
       "1     20726           LUNCH BAG WOODLAND\n",
       "2     22662  LUNCH BAG DOLLY GIRL DESIGN\n",
       "3     23207    LUNCH BAG ALPHABET DESIGN\n",
       "4     20719       WOODLAND CHARLOTTE BAG\n",
       "5     22383      LUNCH BAG SUKI  DESIGN \n",
       "6     20728          LUNCH BAG CARS BLUE\n",
       "7     23206       LUNCH BAG APPLE DESIGN\n",
       "8     22355    CHARLOTTE BAG SUKI DESIGN\n",
       "9     23209    LUNCH BAG DOILEY PATTERN "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_items(12361, product_train, user_vecs, item_vecs, customers_arr, products_arr, item_lookup,\n",
    "                       num_items = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
